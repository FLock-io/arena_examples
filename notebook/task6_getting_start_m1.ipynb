{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import yaml\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "working_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(working_dir)\n",
    "# used to load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"FLOCK_API_KEY\"] = \"somekey\"\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: False\n",
      "No GPU available. Training will be slow on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available with PyTorch\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {gpu_count}\")\n",
    "    \n",
    "    # Display information about each GPU\n",
    "    for i in range(gpu_count):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "        print(f\"  Total memory: {gpu_properties.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  CUDA Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will be slow on CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Producer: SEEK48\n",
      "<p>FLock introduces SEEK48, an advanced AI idol producer model designed to help idol teams precisely select members, establish unique identities, and develop the most effective debut strategies. From image building and talent matching to fan engagement strategies, AI leverages data analysis and trend forecasting to create idol groups with strong market appeal. Whether shaping group concepts or optimizing individual career paths, our AI ensures that every idol takes the stage in the best possible way to become the next superstar.</p><br/><p>FLock 推出全新的 AI 偶像制作人模型 SEEK48，帮助偶像团队精准筛选成员、确定个性化定位，并制定最优出道方案。从形象塑造、才艺匹配到粉丝策略，AI 将结合数据分析与趋势预测，助力打造具有市场吸引力的偶像团队。无论是策划团体风格，还是优化个人发展路线，我们的AI都让每位偶像都能以最适合的方式站上舞台，成为未来的超级明星。</p><br/><p>FLock은 새로운 AI 아이돌 프로듀서 모델 SEEK48을 출시하여, 아이돌 팀이 멤버를 정교하게 선발하고 개성을 확립하며 최적의 데뷔 전략을 수립할 수 있도록 돕습니다. 이미지 구축부터 재능 매칭, 팬 전략까지, AI는 데이터 분석과 트렌드 예측을 결합하여 시장에서 경쟁력 있는 아이돌 그룹을 탄생시킵니다. 그룹 컨셉 기획부터 개인 성장 최적화까지, 우리의 AI는 각 아이돌이 자신의 강점을 극대화하여 무대에서 빛날 수 있도록 지원합니다.</p><br/><p>FLock は、最新の AI アイドルプロデューサーモデル SEEK48 を発表しました。このモデルは、アイドルチームがメンバーの選定や個性の確立、最適なデビュー戦略の策定を支援します。イメージ構築、才能のマッチング、ファン戦略まで、AI はデータ分析とトレンド予測を活用し、市場で成功するアイドルグループの形成をサポートします。グループのコンセプト設計から個人のキャリアプランの最適化まで、当社の AI は、すべてのアイドルが最も輝く形でステージに立てるよう支援します。</p>\n",
      "{'training_set_url': 'https://fed-ledger-prod-dataset.s3.amazonaws.com/6/training_set.jsonl?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIASSFQ745NLT5K57N2%2F20250321%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20250321T101058Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bffcfd5df7e670905c260d07a7bffa82f28b8f3f931639ee4f4c818e346296b6', 'max_params': 8000000000, 'context_length': 4096}\n",
      "\n",
      "Maximum parameters allowed: 8.0B parameters\n",
      "2025-03-30T23:59:59.975240\n",
      "2025-04-04T23:59:59.975240\n"
     ]
    }
   ],
   "source": [
    "# This cell fetches task information from the Flock API\n",
    "# It retrieves details about a specific task using its ID\n",
    "# The response includes title, description, data, and important dates\n",
    "\n",
    "task_id=\"6\"\n",
    "location = f'https://fed-ledger-prod.flock.io/api/v1/tasks/get?task_id={task_id}'\n",
    "response = requests.get(location)\n",
    "task = json.loads(response.text)\n",
    "data_url = task[\"data\"][\"training_set_url\"]\n",
    "print(task['title'])\n",
    "print(task['description'])\n",
    "print(task['data'])\n",
    "\n",
    "\n",
    "print()\n",
    "max_params = task['data']['max_params']\n",
    "if isinstance(max_params, int):\n",
    "    # Convert to billions and format\n",
    "    params_in_billions = max_params / 1_000_000_000\n",
    "    print(f\"Maximum parameters allowed: {params_in_billions:.1f}B parameters\")\n",
    "else:\n",
    "    print(max_params)\n",
    "\n",
    "print(task['submission_phase_ends_at'])\n",
    "print(task['final_validation_ends_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to /Users/elizabethlui/work/arena_examples/data/task6_demo_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(data_url, stream=True)\n",
    "train_file = f\"{working_dir}/data/task{task_id}_demo_data.jsonl\"\n",
    "os.makedirs(os.path.dirname(train_file), exist_ok=True)\n",
    "with open(train_file, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:  # filter out keep-alive new chunks\n",
    "            f.write(chunk)\n",
    "    f.flush()\n",
    "    os.fsync(f.fileno())\n",
    "print(f\"Data saved successfully to {train_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random item from the dataset:\n",
      "{\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"我们即将出道的偶像团体名为星辰九人组，成员包括主唱李婷、舞蹈担当张宇、RAP担当王浩、视觉担当陈美、领舞赵磊、主R&B演唱周静、领RAP林峰、舞台表现力强的孙娜和多才多艺的黄明。团队成员在一家大型娱乐公司接受了三年的严格训练，涵盖舞蹈、声乐、表演和语言学习。目前，团队已在社交媒体上积累了一定的粉丝基础，但尚未正式出道。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"星辰九人组拥有多元化的成员分工，主唱、舞蹈、RAP和视觉等多方面的专长为团队提供了广泛的发展可能。基于成员们在不同领域的强项，建议出道时推出多样化的音乐风格，如结合流行舞曲与R&B，展现主唱李婷和主R&B演唱周静的实力，同时利用张宇和赵磊的舞蹈能力打造高质量的舞台表演。考虑到社交媒体已有一定粉丝基础，建议在出道前加强与粉丝的互动，提升粉丝活跃度。此外，可以通过精心设计的视觉形象和独特的团队概念，如“星辰”的主题，增强团队辨识度。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"团队在形象管理上，成员们普遍具备时尚感，服装风格倾向现代与未来结合，舞台造型多变但协调。身材管理得当，擅长运用社交媒体展示个人魅力，团队的个性设定是每个成员都有独特的星座特质。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"在形象管理方面，星辰九人组通过现代与未来结合的服装风格及多变的舞台造型，能够吸引不同喜好的观众群体。利用每个成员独特的星座特质可以打造个性鲜明的成员形象，增加粉丝的认同感和好感度。社交媒体上的个人魅力展示有助于提升团队的整体影响力，建议定期推出成员个人和集体的时尚大片、幕后花絮等内容，增强粉丝的黏性。同时，保持团队形象的一致性与个性化的平衡，有利于在视觉上树立鲜明的品牌形象，提升市场竞争力。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"在商业潜力方面，团队成员们拥有不同的特长，能够跨界合作，例如陈美有模特经验，黄明擅长主持，团队有潜力参与综艺节目。此外，粉丝忠诚度高，粉丝数量已突破30万，粉丝活跃度在社交媒体上表现活跃。团队隶属的娱乐公司在市场上具备良好口碑和推广资源。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"星辰九人组在商业潜力方面表现出色。成员的多元特长使团队具备跨界合作的可能性，例如参与综艺节目、广告代言和影视作品，这将有助于增加曝光率和多元收入来源。粉丝基础稳定且活跃，30万粉丝数量为出道奠定了坚实的市场基础。建议娱乐公司利用其良好口碑和推广资源，加强品牌合作和市场推广活动，如参与热门综艺、举办线上线下粉丝见面会等，进一步提升团队的知名度和商业价值。此外，可以开发周边产品和开展代言合作，充分挖掘商业潜力。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"团队具备一定的国际化影响力，部分成员曾参加国际比赛并获得奖项，团队还拥有多语言能力，能够用英语和日语进行沟通和表演。作品方面，团队已经发布了几首高质量的预告单曲，反响良好。\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"星辰九人组的国际化潜力显著，成员的多语言能力和国际比赛奖项为团队打开全球市场提供了有力支持。建议在出道之初就注重国际市场的布局，例如发行多语言版本的歌曲，参与国际音乐节和跨国综艺节目，以提升国际知名度。高质量的预告单曲反响良好，可以借助现有热度进行首发，搭配精彩的音乐视频，提高传播效果。同时，利用部分成员的国际经验和语言优势，开展国际粉丝互动活动，如线上直播、社交媒体互动等，进一步扩大海外粉丝群体。通过这些策略，星辰九人组有望成为具有国际影响力的偶像团体。\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Total number of items in the dataset: 90\n"
     ]
    }
   ],
   "source": [
    "# Load and display a random item from the downloaded JSONL file\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Read all lines from the JSONL file\n",
    "with open(train_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Select a random line\n",
    "random_line = random.choice(lines)\n",
    "\n",
    "# Parse the JSON\n",
    "random_item = json.loads(random_line)\n",
    "\n",
    "# Display the random item\n",
    "print(\"Random item from the dataset:\")\n",
    "print(json.dumps(random_item, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Print the number of items in the dataset\n",
    "print(f\"\\nTotal number of items in the dataset: {len(lines)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arg_file = f\"{working_dir}/args/task{task_id}_training_args.yaml\"\n",
    "with open(train_arg_file, 'r') as f:\n",
    "    all_training_args_as_list = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 8,\n",
       " 'num_train_epochs': 1,\n",
       " 'lora_rank': 8,\n",
       " 'lora_alpha': 16,\n",
       " 'lora_dropout': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the model config that we are going to use\n",
    "use_args = all_training_args_as_list['Qwen/Qwen1.5-0.5B']\n",
    "# use_args['lora_rank'] = 4\n",
    "# use_args['lora_alpha'] = 8\n",
    "use_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_template = {\n",
    "    \"system_format\": \"<|im_start|>system\\n{content}<|im_end|>\\n\",\n",
    "    \"user_format\": \"<|im_start|>user\\n{content}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"assistant_format\": \"{content}<|im_end|>\\n\",\n",
    "    \"tool_format\": \"{content}\",\n",
    "    \"function_format\": \"{content}\",\n",
    "    \"observation_format\": \"<|im_start|>tool\\n{content}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"system\": \"You are a helpful assistant.\",\n",
    "}\n",
    "\n",
    "gemma_template = {\n",
    "    \"system_format\": \"<bos>\",\n",
    "    \"user_format\": \"<start_of_turn>user\\n{content}<end_of_turn>\\n<start_of_turn>model\\n\",\n",
    "    \"assistant_format\": \"{content}<eos>\\n\",\n",
    "    \"tool_format\": \"{content}\",\n",
    "    \"function_format\": \"{content}\",\n",
    "    \"observation_format\": \"<start_of_turn>tool\\n{content}<end_of_turn>\\n<start_of_turn>model\\n\",\n",
    "    \"system\": None,\n",
    "}\n",
    "\n",
    "model2template = {\n",
    "    \"Qwen/Qwen1.5-0.5B\": qwen_template,\n",
    "    \"Qwen/Qwen1.5-1.8B\": qwen_template,\n",
    "    \"Qwen/Qwen1.5-7B\": qwen_template,\n",
    "    \"google/gemma-2b\": gemma_template,\n",
    "    \"google/gemma-7b\": gemma_template,\n",
    "}\n",
    "\n",
    "model2size = {\n",
    "    \"Qwen/Qwen1.5-0.5B\": 620_000_000,\n",
    "    \"Qwen/Qwen1.5-1.8B\": 1_840_000_000,\n",
    "    \"Qwen/Qwen1.5-7B\": 7_720_000_000,\n",
    "    \"google/gemma-2b\": 2_510_000_000,\n",
    "    \"google/gemma-7b\": 8_540_000_000,\n",
    "}\n",
    "\n",
    "model2base_model = {\n",
    "    \"Qwen/Qwen1.5-0.5B\": \"qwen1.5\",\n",
    "    \"Qwen/Qwen1.5-1.8B\": \"qwen1.5\",\n",
    "    \"Qwen/Qwen1.5-7B\": \"qwen1.5\",\n",
    "    \"google/gemma-2b\": \"gemma\",\n",
    "    \"google/gemma-7b\": \"gemma\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFTDataset(Dataset):\n",
    "    def __init__(self, file, tokenizer, max_seq_length, template):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.system_format = template[\"system_format\"]\n",
    "        self.user_format = template[\"user_format\"]\n",
    "        self.assistant_format = template[\"assistant_format\"]\n",
    "        self.tool_format = template[\"tool_format\"]\n",
    "        self.function_format = template[\"function_format\"]\n",
    "        self.observation_format = template[\"observation_format\"]\n",
    "\n",
    "        self.max_seq_length = max_seq_length\n",
    "        # logger.info(\"Loading data: {}\".format(file))\n",
    "        with open(file, \"r\", encoding=\"utf8\") as f:\n",
    "            data_list = f.readlines()\n",
    "        # logger.info(\"There are {} data in dataset\".format(len(data_list)))\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data_list[index]\n",
    "        data = json.loads(data)\n",
    "        input_ids, target_mask = [], []\n",
    "\n",
    "        # setting system information\n",
    "        if self.system_format is not None:\n",
    "            system = data[\"system\"].strip() if \"system\" in data.keys() else self.system\n",
    "\n",
    "            if system is not None:\n",
    "                system_text = self.system_format.format(content=system)\n",
    "                input_ids = self.tokenizer.encode(system_text, add_special_tokens=False)\n",
    "                target_mask = [0] * len(input_ids)\n",
    "\n",
    "        conversations = data[\"conversations\"]\n",
    "\n",
    "        input_buffer = \"\"\n",
    "        for i in range(len(conversations)):\n",
    "            role = conversations[i][\"role\"]\n",
    "            content = conversations[i][\"content\"].strip()\n",
    "\n",
    "            if role != \"assistant\":\n",
    "                if role == \"user\":\n",
    "                    human = self.user_format.format(\n",
    "                        content=content, stop_token=self.tokenizer.eos_token\n",
    "                    )\n",
    "                    input_buffer += human\n",
    "\n",
    "            else:\n",
    "                assistant = self.assistant_format.format(\n",
    "                    content=content, stop_token=self.tokenizer.eos_token\n",
    "                )\n",
    "\n",
    "                input_tokens = self.tokenizer.encode(\n",
    "                    input_buffer, add_special_tokens=False\n",
    "                )\n",
    "                output_tokens = self.tokenizer.encode(\n",
    "                    assistant, add_special_tokens=False\n",
    "                )\n",
    "\n",
    "                input_ids += input_tokens + output_tokens\n",
    "                target_mask += [0] * len(input_tokens) + [1] * len(output_tokens)\n",
    "                input_buffer = \"\"\n",
    "\n",
    "        assert len(input_ids) == len(target_mask)\n",
    "\n",
    "        input_ids = input_ids[: self.max_seq_length]\n",
    "        target_mask = target_mask[: self.max_seq_length]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        assert len(input_ids) == len(target_mask) == len(attention_mask)\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"target_mask\": target_mask,\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "\n",
    "\n",
    "class SFTDataCollator(object):\n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        # Find the maximum length in the batch\n",
    "        lengths = [len(x[\"input_ids\"]) for x in batch if x[\"input_ids\"] is not None]\n",
    "        # Take the maximum length in the batch, if it exceeds max_seq_length, take max_seq_length\n",
    "        batch_max_len = min(max(lengths), self.max_seq_length)\n",
    "\n",
    "        input_ids_batch, attention_mask_batch, target_mask_batch = [], [], []\n",
    "        # Truncate and pad\n",
    "        for x in batch:\n",
    "            input_ids = x[\"input_ids\"]\n",
    "            attention_mask = x[\"attention_mask\"]\n",
    "            target_mask = x[\"target_mask\"]\n",
    "            if input_ids is None:\n",
    "                logger.info(\"some input_ids is None\")\n",
    "                continue\n",
    "            padding_len = batch_max_len - len(input_ids)\n",
    "            # Pad\n",
    "            input_ids = input_ids + [self.pad_token_id] * padding_len\n",
    "            attention_mask = attention_mask + [0] * padding_len\n",
    "            target_mask = target_mask + [0] * padding_len\n",
    "            # Truncate\n",
    "            input_ids = input_ids[: self.max_seq_length]\n",
    "            attention_mask = attention_mask[: self.max_seq_length]\n",
    "            target_mask = target_mask[: self.max_seq_length]\n",
    "\n",
    "            input_ids_batch.append(input_ids)\n",
    "            attention_mask_batch.append(attention_mask)\n",
    "            target_mask_batch.append(target_mask)\n",
    "\n",
    "        # Convert lists to tensors to get the final model input\n",
    "        input_ids_batch = torch.tensor(input_ids_batch, dtype=torch.long)\n",
    "        attention_mask_batch = torch.tensor(attention_mask_batch, dtype=torch.long)\n",
    "        target_mask_batch = torch.tensor(target_mask_batch, dtype=torch.long)\n",
    "        # input_ids_batch = torch.tensor(input_ids_batch, dtype=torch.long, device='cuda:0')\n",
    "        # attention_mask_batch = torch.tensor(attention_mask_batch, dtype=torch.long, device='cuda:0')\n",
    "        # target_mask_batch = torch.tensor(target_mask_batch, dtype=torch.long, device='cuda:0')\n",
    "\n",
    "        labels = torch.where(target_mask_batch == 1, input_ids_batch, -100)\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids_batch,\n",
    "            \"attention_mask\": attention_mask_batch,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LoraTrainingArguments:\n",
    "    per_device_train_batch_size: int\n",
    "    gradient_accumulation_steps: int\n",
    "    num_train_epochs: int\n",
    "    lora_rank: int\n",
    "    lora_alpha: int\n",
    "    lora_dropout: int\n",
    "\n",
    "def train_lora(\n",
    "    model_id: str, context_length: int, training_args: LoraTrainingArguments,\n",
    "    data_file_path: str,\n",
    "    model_output_dir: str,\n",
    "    model_template: dict,\n",
    "    target_module: list = [\"q_proj\", \"v_proj\"],\n",
    "    max_steps: int = None,  # New parameter to limit training steps\n",
    "):\n",
    "    assert model_id in model2template, f\"model_id {model_id} not supported\"\n",
    "    lora_config = LoraConfig(\n",
    "        r=training_args.lora_rank,\n",
    "        target_modules=target_module,\n",
    "        lora_alpha=training_args.lora_alpha,\n",
    "        lora_dropout=training_args.lora_dropout,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    # Load model in 4-bit to do qLoRA\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=False,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    \n",
    "    # Configure training with option to limit steps\n",
    "    train_config = {\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"gradient_accumulation_steps\": training_args.gradient_accumulation_steps,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"bf16\": True,\n",
    "        \"logging_steps\": 20,\n",
    "        \"output_dir\": \"outputs\",\n",
    "        # Change THIS line:\n",
    "        # \"optim\": \"paged_adamw_8bit\",  # bitsandbytes 8-bit\n",
    "        \"optim\": \"adamw_torch_fused\",   # a normal CPU/MPS-friendly optimizer\n",
    "        \"remove_unused_columns\": False,\n",
    "        \"max_seq_length\": context_length,\n",
    "    }\n",
    "    \n",
    "    # Either use max_steps or num_train_epochs\n",
    "    if max_steps is not None:\n",
    "        train_config[\"max_steps\"] = max_steps\n",
    "    else:\n",
    "        train_config[\"num_train_epochs\"] = training_args.num_train_epochs\n",
    "        \n",
    "    training_args = SFTConfig(**train_config)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        # quantization_config=bnb_config,\n",
    "        token=os.environ[\"HF_TOKEN\"],\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = SFTDataset(\n",
    "        file=data_file_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=context_length,\n",
    "        template=model_template,\n",
    "    )\n",
    "\n",
    "    # Define trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        args=training_args,\n",
    "        peft_config=lora_config,\n",
    "        data_collator=SFTDataCollator(tokenizer, max_seq_length=context_length),\n",
    "    )\n",
    "\n",
    "    # Train model with OOM handling\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except (RuntimeError, torch.cuda.OutOfMemoryError) as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(\"Caught OOM error. Saving current model state...\")\n",
    "        else:\n",
    "            print(f\"Error during training: {e}\")\n",
    "        # Save whatever progress was made before the error\n",
    "    \n",
    "    # Save model regardless of whether training completed or was interrupted\n",
    "    try:\n",
    "        trainer.save_model(model_output_dir)\n",
    "        print(f\"Model saved to {model_output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "\n",
    "    # remove checkpoint folder\n",
    "    os.system(\"rm -rf outputs/checkpoint-*\")\n",
    "\n",
    "    # upload lora weights and tokenizer\n",
    "    print(\"Training Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_template = model2template['Qwen/Qwen1.5-0.5B']\n",
    "use_template['system_format'] = None\n",
    "use_template['system'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train the model Qwen/Qwen1.5-0.5B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "                                     \n",
      "100%|██████████| 3/3 [00:28<00:00,  9.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 28.4769, 'train_samples_per_second': 0.843, 'train_steps_per_second': 0.105, 'train_loss': 2.6741933822631836, 'epoch': 0.27}\n",
      "Model saved to /Users/elizabethlui/work/arena_examples/outputs/task6_Qwen/Qwen1.5-0.5B\n",
      "Training Completed.\n"
     ]
    }
   ],
   "source": [
    "no_submission = True\n",
    "target_module = [\"q_proj\", \"v_proj\"] # default\n",
    "max_params = task[\"data\"][\"max_params\"]\n",
    "context_length = task[\"data\"][\"context_length\"]\n",
    "\n",
    "model_id = list(all_training_args_as_list.keys())[0]\n",
    "output_dir = f\"{working_dir}/outputs/task{task_id}_{model_id}\"\n",
    "\n",
    "print(f\"Start to train the model {model_id}...\")\n",
    "try:\n",
    "    train_lora(\n",
    "        model_id=model_id,\n",
    "        context_length=context_length,\n",
    "        training_args=LoraTrainingArguments(**use_args),\n",
    "        data_file_path=train_file,\n",
    "        model_output_dir=output_dir,\n",
    "        target_module=target_module,\n",
    "        model_template=use_template,\n",
    "        max_steps=3\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Proceed to the next model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training-node",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
