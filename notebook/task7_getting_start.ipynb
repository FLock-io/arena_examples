{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/flock-training/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import yaml\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "working_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(working_dir)\n",
    "\n",
    "\n",
    "# used to load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"FLOCK_API_KEY\"] = \"somekey\"\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA TITAN X (Pascal)\n",
      "  Total memory: 11.90 GB\n",
      "  CUDA Capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available with PyTorch\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {gpu_count}\")\n",
    "    \n",
    "    # Display information about each GPU\n",
    "    for i in range(gpu_count):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "        print(f\"  Total memory: {gpu_properties.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  CUDA Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will be slow on CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLock x OneKey: Advancing AI-Driven Smart Contract Security\n",
      "FLock and OneKey are collaborating to launch the first AI-driven smart contract security challenge, combining FLock’s decentralized model training with OneKey’s expertise in blockchain security. By training AI on real-world vulnerabilities and security Q&A data, we aim to build a benchmark dataset and develop models capable of detecting and mitigating risks at scale. Top contributors will be rewarded with OneKey Hardware Wallet - FLock Limited Edition\n",
      "{'training_set_url': 'https://fed-ledger-prod-dataset.s3.amazonaws.com/7/training_set.jsonl?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIASSFQ745NLT5K57N2%2F20250328%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20250328T103625Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3d67fa15b76f1df97271d6e75ddd7e795c44568bb5c70dc3742580faa8aa9b4e', 'max_params': 15000000000, 'context_length': 8192}\n",
      "\n",
      "Maximum parameters allowed: 15.0B parameters\n",
      "2025-04-23T23:59:59.791348\n",
      "2025-04-28T23:59:59.791348\n"
     ]
    }
   ],
   "source": [
    "# This cell fetches task information from the Flock API\n",
    "# It retrieves details about a specific task using its ID\n",
    "# The response includes title, description, data, and important dates\n",
    "\n",
    "task_id=\"7\"\n",
    "location = f'https://fed-ledger-prod.flock.io/api/v1/tasks/get?task_id={task_id}'\n",
    "response = requests.get(location)\n",
    "task = json.loads(response.text)\n",
    "data_url = task[\"data\"][\"training_set_url\"]\n",
    "print(task['title'])\n",
    "print(task['description'])\n",
    "print(task['data'])\n",
    "\n",
    "\n",
    "print()\n",
    "max_params = task['data']['max_params']\n",
    "if isinstance(max_params, int):\n",
    "    # Convert to billions and format\n",
    "    params_in_billions = max_params / 1_000_000_000\n",
    "    print(f\"Maximum parameters allowed: {params_in_billions:.1f}B parameters\")\n",
    "else:\n",
    "    print(max_params)\n",
    "\n",
    "print(task['submission_phase_ends_at'])\n",
    "print(task['final_validation_ends_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to /home/yifan/playground/arena_examples_code/data/task7_demo_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(data_url, stream=True)\n",
    "train_file = f\"{working_dir}/data/task{task_id}_demo_data.jsonl\"\n",
    "os.makedirs(os.path.dirname(train_file), exist_ok=True)\n",
    "with open(train_file, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:  # filter out keep-alive new chunks\n",
    "            f.write(chunk)\n",
    "    f.flush()\n",
    "    os.fsync(f.fileno())\n",
    "print(f\"Data saved successfully to {train_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random item from the dataset:\n",
      "{\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"pragma solidity ^0.8.20;\\n\\ninterface IERC1271 {\\n    function isValidSignature(bytes32 hash, bytes memory signature) external view returns (bytes4 magicValue);\\n}\\n\\ncontract VulnerableContract is IERC1271 {\\n    address owner;\\n    address shadowedOwner;\\n    uint unusedVariable;\\n\\n    function setOwner(address _owner) public {\\n        owner = _owner;\\n    }\\n\\n    function isValidSignature(bytes32 hash, bytes memory signature) external view override returns (bytes4 magicValue) {\\n        if (tx.origin == owner) { \\n            return 0x1626ba7e;\\n        } else {\\n            return 0xffffffff;\\n        }\\n    }\\n\\n    function executeFunction(address target, bytes memory data) public {\\n        require(block.timestamp % 2 == 0, \\\"Only even block timestamps\\\");\\n        (bool success,) = target.call(data);\\n        require(success, \\\"Call failed\\\");\\n    }\\n\\n    function arbitraryFunctionCall() public {\\n        function() external targetFunction;\\n        targetFunction();\\n    }\\n}\\n\\ncontract ShadowingContract {\\n    address owner;\\n    function setShadowedOwner(address _owner) public {\\n        owner = _owner;\\n    }\\n}\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"The analysis of the smart contract revealed several vulnerabilities: \\n\\n1. **Unspecified Function Visibility**: If the visibility of a function is not declared, it defaults to public, which may lead to unintended access permissions exposure.\\n2. **Use of tx.origin for Authorization**: Attackers can perform reentrancy attacks through intermediary contracts, exploiting the original caller.\\n3. **Shadowed State Variables**: This can lead to unexpected behavior as the state variables in a child contract may override those in a parent contract.\\n4. **Unencrypted On-chain Private Data**: Sensitive data stored in the contract can be read by anyone.\\n5. **Unused Variables**: These increase the complexity of the contract and may lead to misinterpretation.\\n\\nTo address these vulnerabilities, the following recommendations were made:\\n\\n1. Explicitly declare the visibility of all functions.\\n2. Use `msg.sender` instead of `tx.origin` for permission checks.\\n3. Avoid using state variables in child contracts with the same names as those in parent contracts.\\n4. Avoid storing sensitive data in plaintext on the blockchain.\\n5. Remove unused variables to simplify the code.\\n\\nThe revised code implementing these recommendations is as follows:\\n\\n```solidity\\npragma solidity ^0.8.20;\\n\\ninterface IERC1271 {\\n    function isValidSignature(bytes32 hash, bytes memory signature) external view returns (bytes4 magicValue);\\n}\\n\\ncontract SecureContract is IERC1271 {\\n    address private owner;\\n\\n    constructor() {\\n        owner = msg.sender;\\n    }\\n\\n    function setOwner(address _owner) external {\\n        require(msg.sender == owner, \\\"Only the owner can set a new owner\\\");\\n        owner = _owner;\\n    }\\n\\n    function isValidSignature(bytes32 hash, bytes memory signature) external view override returns (bytes4 magicValue) {\\n        if (msg.sender == owner) { \\n            return 0x1626ba7e;\\n        } else {\\n            return 0xffffffff;\\n        }\\n    }\\n\\n    function executeFunction(address target, bytes memory data) external {\\n        require(block.timestamp % 2 == 0, \\\"Only even block timestamps\\\");\\n        (bool success,) = target.call(data);\\n        require(success, \\\"Call failed\\\");\\n    }\\n\\n    function arbitraryFunctionCall() external {\\n        // Placeholder for valid code\\n    }\\n}\\n\\ncontract ShadowingContract {\\n    address private shadowedOwner;\\n    function setShadowedOwner(address _owner) external {\\n        shadowedOwner = _owner;\\n    }\\n}\\n```\"\n",
      "    }\n",
      "  ],\n",
      "  \"system\": \"You are a solidity expert, and you are helping a developer to fix the vulnerability in the code.\"\n",
      "}\n",
      "\n",
      "Total number of items in the dataset: 150\n"
     ]
    }
   ],
   "source": [
    "# Load and display a random item from the downloaded JSONL file\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Read all lines from the JSONL file\n",
    "with open(train_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Select a random line\n",
    "random_line = random.choice(lines)\n",
    "\n",
    "# Parse the JSON\n",
    "random_item = json.loads(random_line)\n",
    "\n",
    "# Display the random item\n",
    "print(\"Random item from the dataset:\")\n",
    "print(json.dumps(random_item, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Print the number of items in the dataset\n",
    "print(f\"\\nTotal number of items in the dataset: {len(lines)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arg_file = f\"{working_dir}/args/task{task_id}_training_args.yaml\"\n",
    "with open(train_arg_file, 'r') as f:\n",
    "    all_training_args_as_list = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 8,\n",
       " 'num_train_epochs': 1,\n",
       " 'lora_rank': 8,\n",
       " 'lora_alpha': 16,\n",
       " 'lora_dropout': 0.1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the model config that we are going to use\n",
    "use_args = all_training_args_as_list['Qwen/Qwen1.5-0.5B']\n",
    "# use_args['lora_rank'] = 4\n",
    "# use_args['lora_alpha'] = 8\n",
    "use_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_template = {\n",
    "    \"system_format\": \"<|im_start|>system\\n{content}<|im_end|>\\n\",\n",
    "    \"user_format\": \"<|im_start|>user\\n{content}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"assistant_format\": \"{content}<|im_end|>\\n\",\n",
    "    \"tool_format\": \"{content}\",\n",
    "    \"function_format\": \"{content}\",\n",
    "    \"observation_format\": \"<|im_start|>tool\\n{content}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"system\": \"You are a helpful assistant.\",\n",
    "}\n",
    "\n",
    "gemma_template = {\n",
    "    \"system_format\": \"<bos>\",\n",
    "    \"user_format\": \"<start_of_turn>user\\n{content}<end_of_turn>\\n<start_of_turn>model\\n\",\n",
    "    \"assistant_format\": \"{content}<eos>\\n\",\n",
    "    \"tool_format\": \"{content}\",\n",
    "    \"function_format\": \"{content}\",\n",
    "    \"observation_format\": \"<start_of_turn>tool\\n{content}<end_of_turn>\\n<start_of_turn>model\\n\",\n",
    "    \"system\": None,\n",
    "}\n",
    "\n",
    "model2template = {\n",
    "    \"Qwen/Qwen1.5-0.5B\": qwen_template,\n",
    "    \"Qwen/Qwen1.5-1.8B\": qwen_template,\n",
    "    \"Qwen/Qwen1.5-7B\": qwen_template,\n",
    "    \"google/gemma-2b\": gemma_template,\n",
    "    \"google/gemma-7b\": gemma_template,\n",
    "}\n",
    "\n",
    "model2size = {\n",
    "    \"Qwen/Qwen1.5-0.5B\": 620_000_000,\n",
    "    \"Qwen/Qwen1.5-1.8B\": 1_840_000_000,\n",
    "    \"Qwen/Qwen1.5-7B\": 7_720_000_000,\n",
    "    \"google/gemma-2b\": 2_510_000_000,\n",
    "    \"google/gemma-7b\": 8_540_000_000,\n",
    "}\n",
    "\n",
    "model2base_model = {\n",
    "    \"Qwen/Qwen1.5-0.5B\": \"qwen1.5\",\n",
    "    \"Qwen/Qwen1.5-1.8B\": \"qwen1.5\",\n",
    "    \"Qwen/Qwen1.5-7B\": \"qwen1.5\",\n",
    "    \"google/gemma-2b\": \"gemma\",\n",
    "    \"google/gemma-7b\": \"gemma\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFTDataset(Dataset):\n",
    "    def __init__(self, file, tokenizer, max_seq_length, template):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.system_format = template[\"system_format\"]\n",
    "        self.user_format = template[\"user_format\"]\n",
    "        self.assistant_format = template[\"assistant_format\"]\n",
    "        self.tool_format = template[\"tool_format\"]\n",
    "        self.function_format = template[\"function_format\"]\n",
    "        self.observation_format = template[\"observation_format\"]\n",
    "\n",
    "        self.max_seq_length = max_seq_length\n",
    "        # logger.info(\"Loading data: {}\".format(file))\n",
    "        with open(file, \"r\", encoding=\"utf8\") as f:\n",
    "            data_list = f.readlines()\n",
    "        # logger.info(\"There are {} data in dataset\".format(len(data_list)))\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data_list[index]\n",
    "        data = json.loads(data)\n",
    "        input_ids, target_mask = [], []\n",
    "\n",
    "        # setting system information\n",
    "        if self.system_format is not None:\n",
    "            system = data[\"system\"].strip() if \"system\" in data.keys() else self.system\n",
    "\n",
    "            if system is not None:\n",
    "                system_text = self.system_format.format(content=system)\n",
    "                input_ids = self.tokenizer.encode(system_text, add_special_tokens=False)\n",
    "                target_mask = [0] * len(input_ids)\n",
    "\n",
    "        conversations = data[\"conversations\"]\n",
    "\n",
    "        input_buffer = \"\"\n",
    "        for i in range(len(conversations)):\n",
    "            role = conversations[i][\"role\"]\n",
    "            content = conversations[i][\"content\"].strip()\n",
    "\n",
    "            if role != \"assistant\":\n",
    "                if role == \"user\":\n",
    "                    human = self.user_format.format(\n",
    "                        content=content, stop_token=self.tokenizer.eos_token\n",
    "                    )\n",
    "                    input_buffer += human\n",
    "\n",
    "            else:\n",
    "                assistant = self.assistant_format.format(\n",
    "                    content=content, stop_token=self.tokenizer.eos_token\n",
    "                )\n",
    "\n",
    "                input_tokens = self.tokenizer.encode(\n",
    "                    input_buffer, add_special_tokens=False\n",
    "                )\n",
    "                output_tokens = self.tokenizer.encode(\n",
    "                    assistant, add_special_tokens=False\n",
    "                )\n",
    "\n",
    "                input_ids += input_tokens + output_tokens\n",
    "                target_mask += [0] * len(input_tokens) + [1] * len(output_tokens)\n",
    "                input_buffer = \"\"\n",
    "\n",
    "        assert len(input_ids) == len(target_mask)\n",
    "\n",
    "        input_ids = input_ids[: self.max_seq_length]\n",
    "        target_mask = target_mask[: self.max_seq_length]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        assert len(input_ids) == len(target_mask) == len(attention_mask)\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"target_mask\": target_mask,\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "\n",
    "\n",
    "class SFTDataCollator(object):\n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        # Find the maximum length in the batch\n",
    "        lengths = [len(x[\"input_ids\"]) for x in batch if x[\"input_ids\"] is not None]\n",
    "        # Take the maximum length in the batch, if it exceeds max_seq_length, take max_seq_length\n",
    "        batch_max_len = min(max(lengths), self.max_seq_length)\n",
    "\n",
    "        input_ids_batch, attention_mask_batch, target_mask_batch = [], [], []\n",
    "        # Truncate and pad\n",
    "        for x in batch:\n",
    "            input_ids = x[\"input_ids\"]\n",
    "            attention_mask = x[\"attention_mask\"]\n",
    "            target_mask = x[\"target_mask\"]\n",
    "            if input_ids is None:\n",
    "                logger.info(\"some input_ids is None\")\n",
    "                continue\n",
    "            padding_len = batch_max_len - len(input_ids)\n",
    "            # Pad\n",
    "            input_ids = input_ids + [self.pad_token_id] * padding_len\n",
    "            attention_mask = attention_mask + [0] * padding_len\n",
    "            target_mask = target_mask + [0] * padding_len\n",
    "            # Truncate\n",
    "            input_ids = input_ids[: self.max_seq_length]\n",
    "            attention_mask = attention_mask[: self.max_seq_length]\n",
    "            target_mask = target_mask[: self.max_seq_length]\n",
    "\n",
    "            input_ids_batch.append(input_ids)\n",
    "            attention_mask_batch.append(attention_mask)\n",
    "            target_mask_batch.append(target_mask)\n",
    "\n",
    "        # Convert lists to tensors to get the final model input\n",
    "        input_ids_batch = torch.tensor(input_ids_batch, dtype=torch.long)\n",
    "        attention_mask_batch = torch.tensor(attention_mask_batch, dtype=torch.long)\n",
    "        target_mask_batch = torch.tensor(target_mask_batch, dtype=torch.long)\n",
    "        # input_ids_batch = torch.tensor(input_ids_batch, dtype=torch.long, device='cuda:0')\n",
    "        # attention_mask_batch = torch.tensor(attention_mask_batch, dtype=torch.long, device='cuda:0')\n",
    "        # target_mask_batch = torch.tensor(target_mask_batch, dtype=torch.long, device='cuda:0')\n",
    "\n",
    "        labels = torch.where(target_mask_batch == 1, input_ids_batch, -100)\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids_batch,\n",
    "            \"attention_mask\": attention_mask_batch,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LoraTrainingArguments:\n",
    "    per_device_train_batch_size: int\n",
    "    gradient_accumulation_steps: int\n",
    "    num_train_epochs: int\n",
    "    lora_rank: int\n",
    "    lora_alpha: int\n",
    "    lora_dropout: int\n",
    "\n",
    "def train_lora(\n",
    "    model_id: str, context_length: int, training_args: LoraTrainingArguments,\n",
    "    data_file_path: str,\n",
    "    model_output_dir: str,\n",
    "    model_template: dict,\n",
    "    target_module: list = [\"q_proj\", \"v_proj\"],\n",
    "    max_steps: int = None,  # New parameter to limit training steps\n",
    "):\n",
    "    assert model_id in model2template, f\"model_id {model_id} not supported\"\n",
    "    lora_config = LoraConfig(\n",
    "        r=training_args.lora_rank,\n",
    "        target_modules=target_module,\n",
    "        lora_alpha=training_args.lora_alpha,\n",
    "        lora_dropout=training_args.lora_dropout,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    # Load model in 4-bit to do qLoRA\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    \n",
    "    # Configure training with option to limit steps\n",
    "    train_config = {\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"gradient_accumulation_steps\": training_args.gradient_accumulation_steps,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"bf16\": True,\n",
    "        \"logging_steps\": 20,\n",
    "        \"output_dir\": \"outputs\",\n",
    "        \"optim\": \"paged_adamw_8bit\",\n",
    "        \"remove_unused_columns\": False,\n",
    "        \"max_seq_length\": context_length,\n",
    "    }\n",
    "    \n",
    "    # Either use max_steps or num_train_epochs\n",
    "    if max_steps is not None:\n",
    "        train_config[\"max_steps\"] = max_steps\n",
    "    else:\n",
    "        train_config[\"num_train_epochs\"] = training_args.num_train_epochs\n",
    "        \n",
    "    training_args = SFTConfig(**train_config)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        token=os.environ[\"HF_TOKEN\"],\n",
    "    )\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = SFTDataset(\n",
    "        file=data_file_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=context_length,\n",
    "        template=model_template,\n",
    "    )\n",
    "\n",
    "    # Define trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        args=training_args,\n",
    "        peft_config=lora_config,\n",
    "        data_collator=SFTDataCollator(tokenizer, max_seq_length=context_length),\n",
    "    )\n",
    "\n",
    "    # Train model with OOM handling\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except (RuntimeError, torch.cuda.OutOfMemoryError) as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(\"Caught OOM error. Saving current model state...\")\n",
    "        else:\n",
    "            print(f\"Error during training: {e}\")\n",
    "        # Save whatever progress was made before the error\n",
    "    \n",
    "    # Save model regardless of whether training completed or was interrupted\n",
    "    try:\n",
    "        trainer.save_model(model_output_dir)\n",
    "        print(f\"Model saved to {model_output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "\n",
    "    # remove checkpoint folder\n",
    "    os.system(\"rm -rf outputs/checkpoint-*\")\n",
    "\n",
    "    # upload lora weights and tokenizer\n",
    "    print(\"Training Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_template = model2template['Qwen/Qwen1.5-0.5B']\n",
    "\n",
    "# in some tasks, the system prompt is not needed - we need this for task 7\n",
    "# use_template['system_format'] = None\n",
    "# use_template['system'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train the model Qwen/Qwen1.5-0.5B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught OOM error. Saving current model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/yifan/playground/arena_examples_code/outputs/task7_Qwen/Qwen1.5-0.5B\n",
      "Training Completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "no_submission = True\n",
    "target_module = [\"q_proj\", \"v_proj\"] # default\n",
    "max_params = task[\"data\"][\"max_params\"]\n",
    "context_length = task[\"data\"][\"context_length\"]\n",
    "\n",
    "model_id = list(all_training_args_as_list.keys())[0]\n",
    "output_dir = f\"{working_dir}/outputs/task{task_id}_{model_id}\"\n",
    "\n",
    "print(f\"Start to train the model {model_id}...\")\n",
    "try:\n",
    "    train_lora(\n",
    "        model_id=model_id,\n",
    "        context_length=context_length,\n",
    "        training_args=LoraTrainingArguments(**use_args),\n",
    "        data_file_path=train_file,\n",
    "        model_output_dir=output_dir,\n",
    "        target_module=target_module,\n",
    "        model_template=use_template,\n",
    "        max_steps=3\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Proceed to the next model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flock-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
